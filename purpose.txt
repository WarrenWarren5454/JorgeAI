The purpose of this project is to assist me in my daily duties as a University of Houston Help Desk Analyst

Common pain points I wish to reduce:
- Looking for an obscure phone number (commonly have to visit the website and scroll to find it)
- Using the UH Directory at https://www.uh.edu/directory/


What is the best system for doing this? I don't want to manually add phone numbers as it is a dynamic job that involves random requests for obscure contacts.

Here is how I want it to look as I already have an electron app setup with the search query and Gemini API (dont give me any code, just explain)

1. Open Electron app
2. Click on search bar
3. Create query for the phone number
4. AI will check cache for a phone number that fits the query, if it doesnt find it - continue
Ex: Query: "Housing" -> AI breaks it down as "Organization: University of Houston, Department: Housing, Phone number: xxx-xxx-xxxx" - returns phone number. A validation prompt (Good or bad response?) will pop up, if it was a good response, add to the cache.
5. If it is not in the cache, have custom search API return the links of the top 2 websites, give website data to the AI to interpret. It should be able to handle multiple phone numbers and select the correct one. For example, if there is a "main line" phone number, a fax number, and a irrelevant number it should just the main one based on context
6. AI returns the result, workflow #4 is executed (to determine if it goes to the cache)

Hereâ€™s a highâ€‘level architecture and workflow you can implement on top of your existing Electron/Gemini setupâ€”no code, just concepts:

1. Frontâ€‘End (Electron Renderer)
Search Bar UI
A simple input field where you type â€œHousing,â€ â€œRegistrar,â€ etc.

Results & Validation Dialog
Once a phone number is returned, pop up a quick â€œGood/Badâ€ feedback button right below it.

2. IPC Bridge to Main Process
Whenever you hit Enter (or click Search), send that query string via Electronâ€™s IPC to a single backâ€‘end handler in the Main process.

3. Cache Layer
Storage Choice

Lightweight: a local SQLite file or even a JSON/LevelDB store.

Semantic lookup: optionally pair it with a tiny vector index (e.g. use embeddings + a small vector DB) so synonyms (â€œhousing,â€ â€œdorms,â€ â€œresidence lifeâ€) still hit cached entries.

Key Schema
Store each entry as { org: "University of Houston", dept: "Housing", phone: "713â€‘###â€‘####", aliases: [...], lastValid: timestamp }.

Lookup Logic

Normalize the query (lowercase, strip stopâ€‘words).

First attempt exact or fuzzy lookup in your cache.

If confidence â‰¥ threshold, return that.

4. â€œMissâ€ â†’ External Search + Scraping
If the cache misses (or confidence is low):

Custom Search API Call
Ask Geminiâ€™s searchâ€‘wrapper to hit topÂ 2 UHâ€‘related pages (e.g. UH Directory and departmental site).

Page Fetch & Phone Extraction
Use a tiny HTML parser + phoneâ€‘regex to pull out all numbers on those two pages.

5. Disambiguation via LLM
Structured Prompt

sql
Copy
Edit
â€œI queried â€˜Housingâ€™ for UH. Here are extracted numbers from these URLs:
 - Fiftyâ€‘five possible numbers: [(123) 456â€‘7890, (713) 743â€‘5470 (main line), â€¦]
Please identify the single main department phone number and return only the digits.â€
LLM Returns
e.g. â€œ7137435470â€

6. Show & Validate
Display that candidate to the user with a â€œğŸ‘ Good / ğŸ‘ Badâ€ prompt.

If user clicks Good, go to stepÂ 7.

If Bad, optionally let them type the correct one or flag as â€œunable to findâ€â€”so you donâ€™t cache a wrong entry.

7. Cache Ingestion
When validated Good:

Insert (or update) your cache store with:

org: â€œUniversity of Houstonâ€

dept: whatever the LLM mapped (Housing)

phone: the validated number

aliases: record the original query text

lastValid: todayâ€™s timestamp

Next time someone searches any of those aliases, youâ€™ll get an instant hit.

8. Optional Enhancements
Background Refresh
Periodically reâ€‘scrape and reâ€‘validate highâ€‘use entries so numbers donâ€™t go stale.

Usage Metrics
Track how often each entry is used; surface the â€œTopÂ 10â€ mostâ€‘queried departments for a oneâ€‘click list.

Synonym Expansion
Have the LLM suggest additional query aliases (â€œres life,â€ â€œonâ€‘campus housingâ€) and seed them in your cache automatically after a good validation.

Why This Works
Dynamic & Scalable
You never hardâ€‘code numbersâ€”they enter your system only after real use and confirmation.

Fast, Semantic Cache
Users get immediate results for repeat queries, including fuzzy matches.

AIâ€‘Driven Discovery
When the cache fails, the LLM plus lightweight scraping handles the heavy lifting.

Quality Control
A oneâ€‘click feedback loop keeps your cache accurate over time.

Maintainable
All storage is local; nothing manual to update unless a department splits or renames itselfâ€”at which point the background refresh (or a single new validation) handles it.

With this architecture, your Electron app remains a simple shell around:

UI â†’ IPC â†’ Cache Lookup â†’ (miss) Search & LLM â†’ Validation â†’ Cache Insert â†’ UI

That minimal orchestration gives you a truly dynamic, selfâ€‘growing phoneâ€‘number assistant without ever handâ€‘typing a directory.








